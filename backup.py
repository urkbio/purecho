#!/usr/bin/env python3
"""
Plog æ•°æ®å¤‡ä»½å·¥å…·
æ”¯æŒå¯¼å‡ºå’Œå¯¼å…¥æ‰€æœ‰åšå®¢æ•°æ®
"""

import os
import sys
import json
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app import app, db
from models import Post, Tag

def export_data(output_file=None):
    """å¯¼å‡ºæ‰€æœ‰æ•°æ®åˆ°JSONæ–‡ä»¶"""
    with app.app_context():
        try:
            # è·å–æ‰€æœ‰æ•°æ®
            posts = Post.query.all()
            tags = Tag.query.all()
            
            # æ„å»ºå¯¼å‡ºæ•°æ®ç»“æ„
            export_data = {
                'version': '1.0',
                'exported_at': datetime.now().isoformat(),
                'posts': [],
                'tags': []
            }
            
            # å¯¼å‡ºæ ‡ç­¾
            for tag in tags:
                tag_data = {
                    'id': tag.id,
                    'name': tag.name
                }
                export_data['tags'].append(tag_data)
            
            # å¯¼å‡ºæ–‡ç« 
            for post in posts:
                post_data = {
                    'id': post.id,
                    'title': post.title,
                    'content': post.content,
                    'created_at': post.created_at.isoformat(),
                    'updated_at': post.updated_at.isoformat(),
                    'is_page': post.is_page,
                    'slug': post.slug,
                    'tags': [tag.name for tag in post.tags]
                }
                export_data['posts'].append(post_data)
            
            # ç”Ÿæˆæ–‡ä»¶ååˆ°backupsæ–‡ä»¶å¤¹
            if not output_file:
                output_file = f'plog_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            
            # ç¡®ä¿backupsæ–‡ä»¶å¤¹å­˜åœ¨
            backups_dir = os.path.join(os.getcwd(), 'backups')
            os.makedirs(backups_dir, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶åˆ°backupsæ–‡ä»¶å¤¹
            output_path = os.path.join(backups_dir, output_file)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f'âœ… æ•°æ®å¯¼å‡ºæˆåŠŸï¼')
            print(f'ğŸ“ æ–‡ä»¶ï¼šbackups/{output_file}')
            print(f'ğŸ“Š ç»Ÿè®¡ï¼š{len(posts)} ç¯‡æ–‡ç« ï¼Œ{len(tags)} ä¸ªæ ‡ç­¾')
            
        except Exception as e:
            print(f'âŒ å¯¼å‡ºå¤±è´¥ï¼š{str(e)}')
            return False
    
    return True

def import_data(input_file, force=False):
    """ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®"""
    with app.app_context():
        try:
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
            if not os.path.isabs(input_file):
                # å¦‚æœä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå…ˆå°è¯•åœ¨backupsæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾
                backups_path = os.path.join(os.getcwd(), 'backups', input_file)
                if os.path.exists(backups_path):
                    input_file = backups_path
                else:
                    # å¦‚æœbackupsæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰ï¼Œå°è¯•å½“å‰ç›®å½•
                    current_path = os.path.join(os.getcwd(), input_file)
                    if os.path.exists(current_path):
                        input_file = current_path
            
            # è¯»å–JSONæ–‡ä»¶
            with open(input_file, 'r', encoding='utf-8') as f:
                import_data = json.load(f)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if not isinstance(import_data, dict) or 'posts' not in import_data or 'tags' not in import_data:
                print('âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„æ•°æ®å­—æ®µ')
                return False
            
            print(f'ğŸ“– æ­£åœ¨è¯»å–å¤‡ä»½æ–‡ä»¶ï¼š{input_file}')
            print(f'ğŸ“Š å¤‡ä»½åŒ…å«ï¼š{len(import_data["posts"])} ç¯‡æ–‡ç« ï¼Œ{len(import_data["tags"])} ä¸ªæ ‡ç­¾')
            
            if not force:
                confirm = input('âš ï¸  è¿™å°†å¯¼å…¥æ•°æ®åˆ°å½“å‰æ•°æ®åº“ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ')
                if confirm.lower() != 'y':
                    print('âŒ æ“ä½œå·²å–æ¶ˆ')
                    return False
            
            # å¼€å§‹å¯¼å…¥
            imported_count = 0
            
            # å¯¼å…¥æ ‡ç­¾
            tag_map = {}  # ç”¨äºæ˜ å°„æ—§IDåˆ°æ–°ID
            for tag_data in import_data.get('tags', []):
                existing_tag = Tag.query.filter_by(name=tag_data['name']).first()
                if not existing_tag:
                    new_tag = Tag(name=tag_data['name'])
                    db.session.add(new_tag)
                    db.session.flush()  # è·å–æ–°ID
                    tag_map[tag_data['id']] = new_tag.id
                    imported_count += 1
                    print(f'  â• åˆ›å»ºæ ‡ç­¾ï¼š{tag_data["name"]}')
                else:
                    tag_map[tag_data['id']] = existing_tag.id
                    print(f'  â­ï¸  è·³è¿‡å·²å­˜åœ¨æ ‡ç­¾ï¼š{tag_data["name"]}')
            
            # å¯¼å…¥æ–‡ç« 
            for post_data in import_data.get('posts', []):
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒslugçš„æ–‡ç« 
                existing_post = Post.query.filter_by(slug=post_data['slug']).first()
                if existing_post:
                    print(f'  â­ï¸  è·³è¿‡å·²å­˜åœ¨æ–‡ç« ï¼š{post_data["title"]}')
                    continue
                
                # åˆ›å»ºæ–°æ–‡ç« 
                new_post = Post(
                    title=post_data['title'],
                    content=post_data['content'],
                    is_page=post_data['is_page'],
                    slug=post_data['slug']
                )
                
                # è®¾ç½®æ—¶é—´
                try:
                    new_post.created_at = datetime.fromisoformat(post_data['created_at'])
                    new_post.updated_at = datetime.fromisoformat(post_data['updated_at'])
                except:
                    pass  # ä½¿ç”¨é»˜è®¤æ—¶é—´
                
                # æ·»åŠ æ ‡ç­¾
                for tag_name in post_data.get('tags', []):
                    tag = Tag.query.filter_by(name=tag_name).first()
                    if tag:
                        new_post.tags.append(tag)
                
                db.session.add(new_post)
                imported_count += 1
                print(f'  â• å¯¼å…¥æ–‡ç« ï¼š{post_data["title"]}')
            
            db.session.commit()
            print(f'âœ… æ•°æ®å¯¼å…¥æˆåŠŸï¼å…±å¯¼å…¥ {imported_count} æ¡è®°å½•')
            
        except FileNotFoundError:
            print(f'âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_file}')
            print('ğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•å°†æ–‡ä»¶æ”¾åœ¨ backups/ æ–‡ä»¶å¤¹ä¸­')
            return False
        except json.JSONDecodeError:
            print('âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šä¸æ˜¯æœ‰æ•ˆçš„JSONæ–‡ä»¶')
            return False
        except Exception as e:
            db.session.rollback()
            print(f'âŒ å¯¼å…¥å¤±è´¥ï¼š{str(e)}')
            return False
    
    return True

def main():
    parser = argparse.ArgumentParser(description='Plog æ•°æ®å¤‡ä»½å·¥å…·')
    parser.add_argument('action', choices=['export', 'import'], help='æ“ä½œç±»å‹')
    parser.add_argument('file', nargs='?', help='æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--force', '-f', action='store_true', help='å¼ºåˆ¶å¯¼å…¥ï¼ˆè·³è¿‡ç¡®è®¤ï¼‰')
    
    args = parser.parse_args()
    
    if args.action == 'export':
        export_data(args.file)
    elif args.action == 'import':
        if not args.file:
            print('âŒ å¯¼å…¥æ“ä½œéœ€è¦æŒ‡å®šæ–‡ä»¶è·¯å¾„')
            sys.exit(1)
        import_data(args.file, args.force)

if __name__ == '__main__':
    main() 